{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading notebook\n",
    "###### Code Ocean use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mreload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Union, Dict, List, Optional, Tuple\n",
    "import tqdm\n",
    "\n",
    "from aind_dynamic_foraging_data_utils import nwb_utils as nu\n",
    "import aind_dynamic_foraging_basic_analysis.licks.annotation as a\n",
    "# Add this at the top of your notebook\n",
    "import sys\n",
    "sys.path.insert(0, '/root/capsule/src/utils')\n",
    "import behavior_utils as bu\n",
    "import array_utils as au\n",
    "import load_utils as lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/nickkeesey/Desktop/learning-dynamics-behavior')\n",
    "\n",
    "# Then your original import should work\n",
    "import test_load as tl\n",
    "import process_nwbs as pn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Processing Notebook: \n",
    "###### 1. Use nwb_utils to load nwbs from base directory and create df_trials \n",
    "###### 2. Use session_metrics to compute session metadata and performance metrics from df_trials\n",
    "###### 3. Use download_utils to download the processed DataFrame to a specified filepath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "##### Full Session Processing:\n",
    "\n",
    "##### Single Session Testing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CO atttached data asset as base directory of nwbs to be processed\n",
    "base_dir='/root/capsule/data/foraging_nwb_bonsai'\n",
    "\n",
    "# Set download location for combined DataFrame\n",
    "destination_path = '/root/capsule/data/file_process_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwb = nu.load_nwb_from_filename('/Users/nickkeesey/Desktop/learning-dynamics-behavior/data/769887_2024-11-06_09-39-22.nwb')\n",
    "\n",
    "df_trials = pn.compute_df_trial(nwb)\n",
    "\n",
    "meta_df = pn.compute_df_session_meta(nwb, df_trials)\n",
    "meta_df.columns = meta_df.columns.droplevel(0) # Remove 'metadata' level\n",
    "\n",
    "performance_df = pn.compute_df_session_performance(nwb, df_trials)\n",
    "performance_df.columns = performance_df.columns.droplevel(0) # Remove 'session_stats' level\n",
    "\n",
    "# Convert MultiIndex to flat index before concatenation\n",
    "if isinstance(meta_df.index, pd.MultiIndex):\n",
    "    meta_df = meta_df.reset_index()\n",
    "if isinstance(performance_df.index, pd.MultiIndex):\n",
    "    performance_df = performance_df.reset_index()\n",
    "\n",
    "# Now concatenate the dataframes\n",
    "session_df = pd.concat([meta_df, performance_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df but not in df_compare:\n",
      "set()\n",
      "\n",
      "Columns in df_compare but not in df:\n",
      "{'logistic_Hattori2019_score_std', 'logistic_Hattori2019_bias', 'logistic_Bari2019_score_std', 'session_time', 'logistic_Miller2021_Choice_amp', 'logistic_Bari2019_bias', 'virus', 'logistic_Su2022_RewC_tau', 'logistic_Miller2021_Choice_x_Reward_amp', 'logistic_Miller2021_score_std', 'subject_genotype', 'logistic_Miller2021_Reward_amp', 'results', 'logistic_Bari2019_RewC_amp', 'logistic_Miller2021_Choice_tau', 'abs(logistic_Miller2021_bias)', 'data_source', 'has_ephys', 'logistic_Hattori2019_score_mean', 'logistic_Hattori2019_UnrC_tau', 'hardware', 'abs(logistic_Hattori2019_bias)', 'logistic_Miller2021_Choice_x_Reward_tau', 'avg_trial_length_in_seconds', 'weekday', 'logistic_Miller2021_bias', 'session_name', 'task_type', 'logistic_Hattori2019_RewC_amp', 'logistic_Hattori2019_RewC_tau', 'logistic_Su2022_score_std', 'injections', 'logistic_Bari2019_Choice_amp', 'water_after_session_last_session', 'old_bpod_session', 'fiber_probes', 'logistic_Hattori2019_Choice_amp', 'logistic_Bari2019_score_mean', 'has_video', 'creation_time', 'logistic_Hattori2019_UnrC_amp', 'logistic_Su2022_UnrC_tau', 'logistic_Miller2021_Reward_tau', 'abs(logistic_Su2022_bias)', 'NM_recorded', 'logistic_Bari2019_Choice_tau', 'institute', 'logistic_Hattori2019_Choice_tau', 'co_data_asset_ID', 'session', 'h2o', 'rig_type', 'logistic_Su2022_score_mean', 'room', 'abs(logistic_Bari2019_bias)', 'logistic_Miller2021_score_mean', 'location', 'water_day_total_last_session', 'logistic_Su2022_bias', 'abs(bias_naive)', 'logistic_Bari2019_RewC_tau', 'logistic_Su2022_UnrC_amp', 'results_location', 'logistic_Su2022_RewC_amp', 'docDB_status'}\n",
      "\n",
      "Comparing values for common columns:\n",
      "finished_trials: Same value (within 4 sig figs)\n",
      "  session_df: 171\n",
      "  df_compare: 171\n",
      "session_run_time_in_min: Same value (within 4 sig figs)\n",
      "  session_df: 24\n",
      "  df_compare: 24.0\n",
      "effective_block_length_median: Different values\n",
      "  session_df: 24.0\n",
      "  df_compare: 23.0\n",
      "duration_gocue_stop_max: Same value (within 4 sig figs)\n",
      "  session_df: 6.016416000202298\n",
      "  df_compare: 6.016416000202298\n",
      "rig: Same value (within 4 sig figs)\n",
      "  session_df: 446-8-C\n",
      "  df_compare: 446-8-C\n",
      "current_stage_actual: Same value (within 4 sig figs)\n",
      "  session_df: STAGE_1\n",
      "  df_compare: STAGE_1\n",
      "lick_consistency_mean_finished_trials: Same value (within 4 sig figs)\n",
      "  session_df: 0.9450617283950618\n",
      "  df_compare: 0.9450617283950618\n",
      "current_branch: Same value (within 4 sig figs)\n",
      "  session_df: main\n",
      "  df_compare: main\n",
      "duration_gocue_stop_mean: Same value (within 4 sig figs)\n",
      "  session_df: 2.4965085064073187\n",
      "  df_compare: 2.4965085064073187\n",
      "p_reward_sum_std: Same value (within 4 sig figs)\n",
      "  session_df: 1.1102230246251565e-16\n",
      "  df_compare: 1.1102230246251563e-16\n",
      "effective_block_length_max: Same value (within 4 sig figs)\n",
      "  session_df: 37\n",
      "  df_compare: 37\n",
      "foraging_eff_random_seed: Same value (within 4 sig figs)\n",
      "  session_df: 0.5454545454545454\n",
      "  df_compare: 0.5454545454545454\n",
      "finished_rate: Same value (within 4 sig figs)\n",
      "  session_df: 0.8142857142857143\n",
      "  df_compare: 0.8142857142857143\n",
      "reward_trials: Same value (within 4 sig figs)\n",
      "  session_df: 78\n",
      "  df_compare: 78\n",
      "total_trials: Same value (within 4 sig figs)\n",
      "  session_df: 210\n",
      "  df_compare: 210\n",
      "target_weight_ratio: Same value (within 4 sig figs)\n",
      "  session_df: 0.85\n",
      "  df_compare: 0.85\n",
      "if_consistent_within_session: Same value (within 4 sig figs)\n",
      "  session_df: True\n",
      "  df_compare: True\n",
      "invalid_lick_ratio: Same value (within 4 sig figs)\n",
      "  session_df: 0.4856577645895153\n",
      "  df_compare: 0.4856577645895153\n",
      "duration_iti_min: Same value (within 4 sig figs)\n",
      "  session_df: 1.0529920011758804\n",
      "  df_compare: 1.0529920011758804\n",
      "reaction_time_mean: Same value (within 4 sig figs)\n",
      "  session_df: 0.7580419046479085\n",
      "  df_compare: 0.7580419046479085\n",
      "session_start_time: Different values\n",
      "  session_df: 2024-11-06 09:39:22.535402-08:00\n",
      "  df_compare: 2024-11-06 09:39:22.535402-08:00\n",
      "water_day_total: Same value (within 4 sig figs)\n",
      "  session_df: 0.25\n",
      "  df_compare: 0.25\n",
      "finished_trials_with_autowater: Same value (within 4 sig figs)\n",
      "  session_df: 189\n",
      "  df_compare: 189\n",
      "base_weight: Same value (within 4 sig figs)\n",
      "  session_df: 28.4\n",
      "  df_compare: 28.4\n",
      "ignored_trials: Same value (within 4 sig figs)\n",
      "  session_df: 39\n",
      "  df_compare: 39\n",
      "lickspout_median_pos_x: Both NaN\n",
      "duration_iti_std: Same value (within 4 sig figs)\n",
      "  session_df: 1.9742382679149053\n",
      "  df_compare: 1.9742382679149053\n",
      "early_lick_rate: Same value (within 4 sig figs)\n",
      "  session_df: 0.0611353711790393\n",
      "  df_compare: 0.0611353711790393\n",
      "lickspout_initial_pos_z: Both NaN\n",
      "curriculum_schema_version: Same value (within 4 sig figs)\n",
      "  session_df: 1.0\n",
      "  df_compare: 1.0\n",
      "laser_2_target_areas: Different values\n",
      "  session_df: None\n",
      "  df_compare: nan\n",
      "session_date: Same value (within 4 sig figs)\n",
      "  session_df: 2024-11-06\n",
      "  df_compare: 2024-11-06\n",
      "lickspout_initial_pos_x: Both NaN\n",
      "laser_1_calibration_power: Both NaN\n",
      "reaction_time_median: Same value (within 4 sig figs)\n",
      "  session_df: 0.2823360003530979\n",
      "  df_compare: 0.2823360003530979\n",
      "foraging_eff: Same value (within 4 sig figs)\n",
      "  session_df: 0.5701754385964913\n",
      "  df_compare: 0.5701754385964913\n",
      "duration_gocue_stop_median: Same value (within 4 sig figs)\n",
      "  session_df: 1.4491200000047684\n",
      "  df_compare: 1.4491200000047684\n",
      "laser_2_calibration_power: Both NaN\n",
      "finished_rate_with_autowater: Same value (within 4 sig figs)\n",
      "  session_df: 0.8253275109170306\n",
      "  df_compare: 0.8253275109170306\n",
      "bias_naive: Same value (within 4 sig figs)\n",
      "  session_df: -0.07602339181286555\n",
      "  df_compare: -0.0760233918128655\n",
      "double_dipping_rate_finished_noreward_trials: Same value (within 4 sig figs)\n",
      "  session_df: 0.053763440860215055\n",
      "  df_compare: 0.053763440860215\n",
      "p_reward_contrast_mean: Same value (within 4 sig figs)\n",
      "  session_df: 100.0\n",
      "  df_compare: 100.0\n",
      "water_in_session_total: Both NaN\n",
      "lickspout_movement_range_z: Both NaN\n",
      "water_after_session: Both NaN\n",
      "ignore_rate: Same value (within 4 sig figs)\n",
      "  session_df: 0.18571428571428572\n",
      "  df_compare: 0.1857142857142857\n",
      "duration_gocue_stop_min: Same value (within 4 sig figs)\n",
      "  session_df: 0.9992639999836683\n",
      "  df_compare: 0.9992639999836684\n",
      "weight_after_ratio: Both NaN\n",
      "duration_delay_period_std: Same value (within 4 sig figs)\n",
      "  session_df: 1.1705857224475005\n",
      "  df_compare: 1.1705857224475005\n",
      "reward_rate: Same value (within 4 sig figs)\n",
      "  session_df: 0.45614035087719296\n",
      "  df_compare: 0.4561403508771929\n",
      "duration_delay_period_min: Same value (within 4 sig figs)\n",
      "  session_df: 0.09967999905347824\n",
      "  df_compare: 0.0996799990534782\n",
      "lickspout_median_pos_z: Both NaN\n",
      "effective_block_length_mean: Different values\n",
      "  session_df: 25.444444444444443\n",
      "  df_compare: 25.625\n",
      "double_dipping_rate_finished_trials: Same value (within 4 sig figs)\n",
      "  session_df: 0.1111111111111111\n",
      "  df_compare: 0.1111111111111111\n",
      "effective_block_length_std: Different values\n",
      "  session_df: 7.776190314187863\n",
      "  df_compare: 8.230089610690762\n",
      "p_reware_contrast_median: Same value (within 4 sig figs)\n",
      "  session_df: 100.0\n",
      "  df_compare: 100.0\n",
      "ignore_rate_with_autowater: Same value (within 4 sig figs)\n",
      "  session_df: 0.1746724890829694\n",
      "  df_compare: 0.1746724890829694\n",
      "session_end_time: Same value (within 4 sig figs)\n",
      "  session_df: 2024-11-06 10:04:20.077008\n",
      "  df_compare: 2024-11-06 10:04:20.077008\n",
      "water_in_session_foraging: Same value (within 4 sig figs)\n",
      "  session_df: 0.175\n",
      "  df_compare: 0.175\n",
      "duration_delay_period_mean: Same value (within 4 sig figs)\n",
      "  session_df: 0.37035528395536427\n",
      "  df_compare: 0.3703552839553642\n",
      "curriculum_version: Same value (within 4 sig figs)\n",
      "  session_df: 2.3\n",
      "  df_compare: 2.3\n",
      "curriculum_name: Same value (within 4 sig figs)\n",
      "  session_df: Uncoupled Baiting\n",
      "  df_compare: Uncoupled Baiting\n",
      "lickspout_initial_pos_y: Both NaN\n",
      "laser_1_target_areas: Different values\n",
      "  session_df: None\n",
      "  df_compare: nan\n",
      "p_reward_sum_mean: Same value (within 4 sig figs)\n",
      "  session_df: 0.7999999999999999\n",
      "  df_compare: 0.7999999999999999\n",
      "foraging_performance_random_seed: Same value (within 4 sig figs)\n",
      "  session_df: 0.44415584415584414\n",
      "  df_compare: 0.4441558441558441\n",
      "lickspout_movement_range_x: Both NaN\n",
      "foraging_performance: Same value (within 4 sig figs)\n",
      "  session_df: 0.46428571428571436\n",
      "  df_compare: 0.4642857142857143\n",
      "effective_block_length_min: Same value (within 4 sig figs)\n",
      "  session_df: 15\n",
      "  df_compare: 15\n",
      "repo_url: Same value (within 4 sig figs)\n",
      "  session_df: https://github.com/AllenNeuralDynamics/dynamic-foraging-task.git\n",
      "  df_compare: https://github.com/AllenNeuralDynamics/dynamic-foraging-task.git\n",
      "target_weight: Same value (within 4 sig figs)\n",
      "  session_df: 24.14\n",
      "  df_compare: 24.14\n",
      "task: Same value (within 4 sig figs)\n",
      "  session_df: Coupled Baiting\n",
      "  df_compare: Coupled Baiting\n",
      "nwb_suffix: Same value (within 4 sig figs)\n",
      "  session_df: 93922\n",
      "  df_compare: 93922\n",
      "duration_gocue_stop_std: Same value (within 4 sig figs)\n",
      "  session_df: 1.9079395630478089\n",
      "  df_compare: 1.9079395630478089\n",
      "reward_volume_right_mean: Same value (within 4 sig figs)\n",
      "  session_df: 2.0\n",
      "  df_compare: 2.0\n",
      "lickspout_movement_range_y: Both NaN\n",
      "weight_after: Both NaN\n",
      "subject_id: Same value (within 4 sig figs)\n",
      "  session_df: 769887\n",
      "  df_compare: 769887\n",
      "autowater_collected: Same value (within 4 sig figs)\n",
      "  session_df: 18\n",
      "  df_compare: 18\n",
      "duration_iti_median: Same value (within 4 sig figs)\n",
      "  session_df: 3.184000000357628\n",
      "  df_compare: 3.184000000357628\n",
      "lickspout_median_pos_y: Both NaN\n",
      "double_dipping_rate_finished_reward_trials: Same value (within 4 sig figs)\n",
      "  session_df: 0.16666666666666666\n",
      "  df_compare: 0.1666666666666666\n",
      "commit_ID: Same value (within 4 sig figs)\n",
      "  session_df: 4f4f59556389b4696a28bcbed810dec00816cf61\n",
      "  df_compare: 4f4f59556389b4696a28bcbed810dec00816cf61\n",
      "p_reward_sum_median: Same value (within 4 sig figs)\n",
      "  session_df: 0.8\n",
      "  df_compare: 0.8\n",
      "duration_delay_period_max: Same value (within 4 sig figs)\n",
      "  session_df: 7.151647999882698\n",
      "  df_compare: 7.151647999882698\n",
      "if_overriden_by_trainer: Same value (within 4 sig figs)\n",
      "  session_df: False\n",
      "  df_compare: False\n",
      "duration_iti_mean: Same value (within 4 sig figs)\n",
      "  session_df: 3.655629554535689\n",
      "  df_compare: 3.655629554535689\n",
      "total_trials_with_autowater: Same value (within 4 sig figs)\n",
      "  session_df: 229\n",
      "  df_compare: 229\n",
      "water_in_session_manual: Both NaN\n",
      "reward_volume_left_mean: Same value (within 4 sig figs)\n",
      "  session_df: 2.0\n",
      "  df_compare: 2.0\n",
      "autowater_ignored: Same value (within 4 sig figs)\n",
      "  session_df: 1\n",
      "  df_compare: 1\n",
      "user_name: Same value (within 4 sig figs)\n",
      "  session_df: Huy Nguyen\n",
      "  df_compare: Huy Nguyen\n",
      "lick_consistency_mean_finished_reward_trials: Same value (within 4 sig figs)\n",
      "  session_df: 0.9256944444444445\n",
      "  df_compare: 0.9256944444444444\n",
      "experiment_description: Different values\n",
      "  session_df: \n",
      "  df_compare: nan\n",
      "duration_delay_period_median: Same value (within 4 sig figs)\n",
      "  session_df: 0.10076799988746643\n",
      "  df_compare: 0.1007679998874664\n",
      "notes: Same value (within 4 sig figs)\n",
      "  session_df: 16.7/23/23/18.6\n",
      "  df_compare: 16.7/23/23/18.6\n",
      "lick_consistency_mean_finished_noreward_trials: Same value (within 4 sig figs)\n",
      "  session_df: 0.9650537634408602\n",
      "  df_compare: 0.9650537634408602\n",
      "duration_iti_max: Same value (within 4 sig figs)\n",
      "  session_df: 7.015007998794317\n",
      "  df_compare: 7.015007998794317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/k7gx9xps333170k7zsggl4tw0000gn/T/ipykernel_61423/489206852.py:2: DtypeWarning: Columns (6,7,8,11,26,27,28,29,30,133,134,149,150,151,152,153,154,155,156,157,158,159,160,161) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_compare = pd.read_csv('/Users/nickkeesey/Desktop/learning-dynamics-behavior/data/filtered_data_20241107.csv')\n"
     ]
    }
   ],
   "source": [
    "# Check with real data\n",
    "df_compare = pd.read_csv('/Users/nickkeesey/Desktop/learning-dynamics-behavior/data/filtered_data_20241107.csv')\n",
    "\n",
    "subject = 769887\n",
    "session_date = '2024-11-06'\n",
    "\n",
    "# Flatten the MultiIndex columns in session_df\n",
    "if isinstance(session_df.columns, pd.MultiIndex):\n",
    "    session_df.columns = session_df.columns.get_level_values(-1)\n",
    "\n",
    "df_compare = df_compare[df_compare['subject_id'] == subject]\n",
    "df_compare = df_compare[df_compare['session_date'] == session_date]\n",
    "\n",
    "# Get columns unique to each dataframe\n",
    "df_cols = set(session_df.columns)\n",
    "df_compare_cols = set(df_compare.columns)\n",
    "\n",
    "print(\"Columns in df but not in df_compare:\")\n",
    "print(df_cols - df_compare_cols)\n",
    "print(\"\\nColumns in df_compare but not in df:\")\n",
    "print(df_compare_cols - df_cols)\n",
    "\n",
    "def is_number(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        return False\n",
    "\n",
    "def is_close_enough(val1, val2, sig_figs=4):\n",
    "    if not (is_number(val1) and is_number(val2)):\n",
    "        return val1 == val2\n",
    "    \n",
    "    # Convert to floats\n",
    "    val1, val2 = float(val1), float(val2)\n",
    "    \n",
    "    # Handle zero values\n",
    "    if val1 == 0 or val2 == 0:\n",
    "        return abs(val1 - val2) < 1e-10\n",
    "    \n",
    "    # Calculate relative difference\n",
    "    rel_diff = abs((val1 - val2) / max(abs(val1), abs(val2)))\n",
    "    return rel_diff < 10**(-sig_figs)\n",
    "\n",
    "# Compare values for common columns\n",
    "common_cols = df_cols.intersection(df_compare_cols)\n",
    "print(\"\\nComparing values for common columns:\")\n",
    "for col in common_cols:\n",
    "    session_val = session_df[col].iloc[0]\n",
    "    df_compare_val = df_compare[col].iloc[0]\n",
    "    \n",
    "    if pd.isna(session_val) and pd.isna(df_compare_val):\n",
    "        print(f\"{col}: Both NaN\")\n",
    "    elif is_close_enough(session_val, df_compare_val):\n",
    "        print(f\"{col}: Same value (within 4 sig figs)\")\n",
    "        print(f\"  session_df: {session_val}\")\n",
    "        print(f\"  df_compare: {df_compare_val}\")\n",
    "    else:\n",
    "        print(f\"{col}: Different values\")\n",
    "        print(f\"  session_df: {session_val}\")\n",
    "        print(f\"  df_compare: {df_compare_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Bonsai Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nwb_to_df(nwb_path, nwb_utils, process_nwbs):\n",
    "    \"\"\"Process a single NWB file into a dataframe containing both meta and performance data\n",
    "    \n",
    "    Args:\n",
    "        nwb_path (str): Path to NWB file\n",
    "        nwb_utils: Module containing load_nwb_from_filename function\n",
    "        process_nwbs: Module containing compute functions\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataframe with meta and performance data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load NWB file using provided utility\n",
    "        nwb = nwb_utils.load_nwb_from_filename(nwb_path)\n",
    "        \n",
    "        # Compute trial, meta and performance dataframes\n",
    "        df_trials = process_nwbs.compute_df_trial(nwb)\n",
    "        \n",
    "        meta_df = process_nwbs.compute_df_session_meta(nwb, df_trials)\n",
    "        meta_df.columns = meta_df.columns.droplevel(0)  # Remove 'metadata' level\n",
    "        \n",
    "        performance_df = process_nwbs.compute_df_session_performance(nwb, df_trials) \n",
    "        performance_df.columns = performance_df.columns.droplevel(0)  # Remove 'session_stats' level\n",
    "        \n",
    "        # Convert MultiIndex to flat index before concatenation\n",
    "        if isinstance(meta_df.index, pd.MultiIndex):\n",
    "            meta_df = meta_df.reset_index()\n",
    "        if isinstance(performance_df.index, pd.MultiIndex):\n",
    "            performance_df = performance_df.reset_index()\n",
    "            \n",
    "        # Concatenate the dataframes\n",
    "        session_df = pd.concat([meta_df, performance_df], axis=1)\n",
    "        \n",
    "        return session_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {nwb_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_multiple_nwbs(nwb_dir, nwb_utils, process_nwbs, pattern=\"**/*.nwb\"):\n",
    "    \"\"\"Process multiple NWB files from a directory and combine into one dataframe\n",
    "    \n",
    "    Args:\n",
    "        nwb_dir (str): Directory containing NWB files\n",
    "        nwb_utils: Module containing load_nwb_from_filename function\n",
    "        process_nwbs: Module containing compute functions\n",
    "        pattern (str): Glob pattern to match NWB files. Default \"**/*.nwb\"\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataframe with data from all NWB files\n",
    "    \"\"\"\n",
    "    # Get list of all NWB files\n",
    "    nwb_files = glob.glob(os.path.join(nwb_dir, pattern), recursive=True)\n",
    "    \n",
    "    if not nwb_files:\n",
    "        raise ValueError(f\"No NWB files found in {nwb_dir} matching pattern {pattern}\")\n",
    "        \n",
    "    # Process each NWB file and collect results\n",
    "    all_dfs = []\n",
    "    for nwb_path in tqdm(nwb_files, desc=\"Processing NWB files\"):\n",
    "        df = process_nwb_to_df(nwb_path, nwb_utils, process_nwbs)\n",
    "        if df is not None:\n",
    "            all_dfs.append(df)\n",
    "            \n",
    "    # Combine all dataframes\n",
    "    if not all_dfs:\n",
    "        raise ValueError(\"No valid dataframes were generated from the NWB files\")\n",
    "        \n",
    "    combined_df = pd.concat(all_dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    import nwb_utils as nu  # Module containing load_nwb_from_filename\n",
    "    import process_nwbs as pn  # Module containing compute functions\n",
    "    \n",
    "    # Directory containing NWB files\n",
    "    nwb_directory = \"/root/capsule/data/foraging_nwb_bonsai\"\n",
    "    \n",
    "    try:\n",
    "        # Process all NWB files and get combined dataframe\n",
    "        combined_df = process_multiple_nwbs(nwb_directory, nu, pn)\n",
    "        \n",
    "        # Save to CSV or pickle\n",
    "        combined_df.to_csv(\"combined_session_data.csv\", index=False)\n",
    "        \n",
    "        print(f\"Successfully processed {len(combined_df)} sessions\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in pipeline: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "##### 1. Trial Only Processing with subject_id and session_date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/Main/lib/python3.12/pathlib.py:1311\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1311\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/capsule/scratch'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/Main/lib/python3.12/pathlib.py:1311\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1311\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/capsule'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load nwbs from base directory with filenames matching valid regex patterns \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Returns csv files into scratch folder (default)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_nwb_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/learning-dynamics-behavior/src/utils/load_utils.py:45\u001b[0m, in \u001b[0;36mload_nwb_files\u001b[0;34m(base_dir, process_data, cachedir, filename_pattern)\u001b[0m\n\u001b[1;32m     42\u001b[0m cache_path \u001b[38;5;241m=\u001b[39m Path(cachedir)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Create cache directory\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mcache_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Find all NWB files (including in subdirectories)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m nwb_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(base_path\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.nwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/Main/lib/python3.12/pathlib.py:1315\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1314\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmkdir(mode, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Main/lib/python3.12/pathlib.py:1315\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1314\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmkdir(mode, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Main/lib/python3.12/pathlib.py:1311\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1311\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/root'"
     ]
    }
   ],
   "source": [
    "# Load nwbs from base directory with filenames matching valid regex patterns \n",
    "# Returns csv files into scratch folder (default)\n",
    "lu.load_nwb_files(base_dir = base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not extract metadata from 0_2024-11-21.csv\n",
      "Could not extract metadata from 1_2024-09-30.csv\n",
      "Could not extract metadata from 45678_2024-09-11.csv\n",
      "Could not extract metadata from 1_2024-04-13.csv\n",
      "Could not extract metadata from 1_2024-09-16.csv\n",
      "Could not extract metadata from 3_2024-09-23.csv\n",
      "Could not extract metadata from 23456789_2024-10-31.csv\n",
      "Could not extract metadata from 324567890_2024-10-31.csv\n",
      "Could not extract metadata from 3_2024-10-21.csv\n",
      "Could not extract metadata from 5_2024-09-09.csv\n",
      "Could not extract metadata from 0_2024-12-04.csv\n",
      "Could not extract metadata from 2_2024-08-14.csv\n",
      "Could not extract metadata from 2_2024-08-05.csv\n",
      "Could not extract metadata from 324567890_2024-11-01.csv\n",
      "Could not extract metadata from 1_2024-04-19.csv\n",
      "Could not extract metadata from 3_2024-10-07.csv\n",
      "Could not extract metadata from 1_2024-04-06.csv\n",
      "Could not extract metadata from 1_2024-08-19.csv\n",
      "Could not extract metadata from 2345678_2024-11-01.csv\n",
      "Could not extract metadata from 0_2024-11-22.csv\n",
      "Could not extract metadata from 4_2024-09-09.csv\n",
      "Could not extract metadata from 3_2024-11-18.csv\n",
      "Could not extract metadata from 05_2023-11-08.csv\n",
      "Could not extract metadata from 11_2024-08-13.csv\n",
      "Could not extract metadata from 1_2024-08-05.csv\n",
      "Could not extract metadata from 3_2024-08-30.csv\n",
      "Could not extract metadata from 2_2024-09-30.csv\n",
      "Could not extract metadata from 1_2024-08-14.csv\n",
      "Could not extract metadata from 4_2024-10-14.csv\n",
      "Could not extract metadata from 2_2024-10-07.csv\n",
      "Could not extract metadata from 1_2024-11-25.csv\n",
      "Could not extract metadata from 4_2024-09-23.csv\n",
      "Could not extract metadata from 1_2024-08-09.csv\n",
      "Could not extract metadata from 1_2024-09-17.csv\n",
      "Could not extract metadata from 6_2024-09-09.csv\n",
      "Could not extract metadata from 0_2024-11-15.csv\n",
      "Could not extract metadata from 1_2024-08-30.csv\n",
      "Could not extract metadata from 0_2024-11-19.csv\n",
      "Could not extract metadata from 23456789_2024-10-25.csv\n",
      "Could not extract metadata from 3_2024-08-09.csv\n",
      "Could not extract metadata from 2_2024-08-19.csv\n",
      "Could not extract metadata from 8_2024-11-19.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>animal_response</th>\n",
       "      <th>rewarded_historyL</th>\n",
       "      <th>rewarded_historyR</th>\n",
       "      <th>bait_left</th>\n",
       "      <th>bait_right</th>\n",
       "      <th>base_reward_probability_sum</th>\n",
       "      <th>reward_probabilityL</th>\n",
       "      <th>reward_probabilityR</th>\n",
       "      <th>reward_random_number_left</th>\n",
       "      <th>...</th>\n",
       "      <th>reward_time_in_session</th>\n",
       "      <th>reward_time_in_trial</th>\n",
       "      <th>choice_time_in_session</th>\n",
       "      <th>choice_time_in_trial</th>\n",
       "      <th>earned_reward</th>\n",
       "      <th>extra_reward</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>session_date</th>\n",
       "      <th>reward_delay</th>\n",
       "      <th>minimum_opto_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.789076</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>687553</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.518192</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>687553</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.367511</td>\n",
       "      <td>...</td>\n",
       "      <td>16.160096</td>\n",
       "      <td>0.487072</td>\n",
       "      <td>16.153088</td>\n",
       "      <td>0.480064</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>687553</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.053372</td>\n",
       "      <td>...</td>\n",
       "      <td>25.333088</td>\n",
       "      <td>0.376064</td>\n",
       "      <td>25.331872</td>\n",
       "      <td>0.374848</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>687553</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.955191</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.364160</td>\n",
       "      <td>0.157440</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>687553</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577768</th>\n",
       "      <td>582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.700221</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5378.042624</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>724555</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577769</th>\n",
       "      <td>583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.678467</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>724555</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577770</th>\n",
       "      <td>584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050451</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5392.707232</td>\n",
       "      <td>0.347424</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>724555</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577771</th>\n",
       "      <td>585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.118763</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5404.919264</td>\n",
       "      <td>0.359232</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>724555</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577772</th>\n",
       "      <td>586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.130339</td>\n",
       "      <td>...</td>\n",
       "      <td>5410.429088</td>\n",
       "      <td>0.219136</td>\n",
       "      <td>5410.427904</td>\n",
       "      <td>0.217952</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>724555</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2577773 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         trial  animal_response  rewarded_historyL  rewarded_historyR  \\\n",
       "0            0              2.0              False              False   \n",
       "1            1              2.0              False              False   \n",
       "2            2              0.0               True              False   \n",
       "3            3              0.0               True              False   \n",
       "4            4              0.0              False              False   \n",
       "...        ...              ...                ...                ...   \n",
       "2577768    582              1.0              False              False   \n",
       "2577769    583              2.0              False              False   \n",
       "2577770    584              1.0              False              False   \n",
       "2577771    585              1.0              False              False   \n",
       "2577772    586              0.0               True              False   \n",
       "\n",
       "         bait_left  bait_right  base_reward_probability_sum  \\\n",
       "0            False       False                         0.45   \n",
       "1            False       False                         0.45   \n",
       "2             True       False                         0.45   \n",
       "3             True       False                         0.45   \n",
       "4            False       False                         0.45   \n",
       "...            ...         ...                          ...   \n",
       "2577768      False       False                         0.45   \n",
       "2577769      False       False                         0.45   \n",
       "2577770       True       False                         0.45   \n",
       "2577771       True       False                         0.45   \n",
       "2577772       True       False                         0.45   \n",
       "\n",
       "         reward_probabilityL  reward_probabilityR  reward_random_number_left  \\\n",
       "0                        0.4                 0.05                   0.789076   \n",
       "1                        0.4                 0.05                   0.518192   \n",
       "2                        0.4                 0.05                   0.367511   \n",
       "3                        0.4                 0.05                   0.053372   \n",
       "4                        0.4                 0.05                   0.955191   \n",
       "...                      ...                  ...                        ...   \n",
       "2577768                  0.4                 0.05                   0.700221   \n",
       "2577769                  0.4                 0.05                   0.678467   \n",
       "2577770                  0.4                 0.05                   0.050451   \n",
       "2577771                  0.4                 0.05                   0.118763   \n",
       "2577772                  0.4                 0.05                   0.130339   \n",
       "\n",
       "         ...  reward_time_in_session  reward_time_in_trial  \\\n",
       "0        ...                     NaN                   NaN   \n",
       "1        ...                     NaN                   NaN   \n",
       "2        ...               16.160096              0.487072   \n",
       "3        ...               25.333088              0.376064   \n",
       "4        ...                     NaN                   NaN   \n",
       "...      ...                     ...                   ...   \n",
       "2577768  ...                     NaN                   NaN   \n",
       "2577769  ...                     NaN                   NaN   \n",
       "2577770  ...                     NaN                   NaN   \n",
       "2577771  ...                     NaN                   NaN   \n",
       "2577772  ...             5410.429088              0.219136   \n",
       "\n",
       "         choice_time_in_session  choice_time_in_trial  earned_reward  \\\n",
       "0                           NaN                   NaN          False   \n",
       "1                           NaN                   NaN          False   \n",
       "2                     16.153088              0.480064           True   \n",
       "3                     25.331872              0.374848           True   \n",
       "4                     34.364160              0.157440          False   \n",
       "...                         ...                   ...            ...   \n",
       "2577768             5378.042624              0.199680          False   \n",
       "2577769                     NaN                   NaN          False   \n",
       "2577770             5392.707232              0.347424          False   \n",
       "2577771             5404.919264              0.359232          False   \n",
       "2577772             5410.427904              0.217952           True   \n",
       "\n",
       "         extra_reward  subject_id  session_date  reward_delay  \\\n",
       "0               False      687553    2023-12-01           NaN   \n",
       "1               False      687553    2023-12-01           NaN   \n",
       "2               False      687553    2023-12-01           NaN   \n",
       "3               False      687553    2023-12-01           NaN   \n",
       "4               False      687553    2023-12-01           NaN   \n",
       "...               ...         ...           ...           ...   \n",
       "2577768         False      724555    2024-07-10           0.0   \n",
       "2577769         False      724555    2024-07-10           0.0   \n",
       "2577770         False      724555    2024-07-10           0.0   \n",
       "2577771         False      724555    2024-07-10           0.0   \n",
       "2577772         False      724555    2024-07-10           0.0   \n",
       "\n",
       "         minimum_opto_interval  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "...                        ...  \n",
       "2577768                    0.0  \n",
       "2577769                    0.0  \n",
       "2577770                    0.0  \n",
       "2577771                    0.0  \n",
       "2577772                    0.0  \n",
       "\n",
       "[2577773 rows x 83 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set source path for combined Pandas DataFrame creation\n",
    "source_path = '/root/capsule/scratch'\n",
    "\n",
    "# Create concatenated DataFrame using CSV files in source path\n",
    "# Add subject_id and session_date categorical columns based on filename\n",
    "processed_nwb_df = lu.process_csv_files(source_path)\n",
    "print(processed_nwb_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set download location for combined DataFrame\n",
    "filepath = '/root/capsule/data/file_process_output'\n",
    "\n",
    "# Download DataFrame to selected filepath \n",
    "downloaded_path = lu.download_dataframe_to_csv(\n",
    "    processed_nwb_df, \n",
    "    filepath=filepath, \n",
    "    filename='foraging_trials_bonsai.csv', \n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 40 bytes\n"
     ]
    }
   ],
   "source": [
    "# Check downloaded size \n",
    "\n",
    "file_size = os.path.getsize(filepath)\n",
    "print(\"File size:\", file_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
